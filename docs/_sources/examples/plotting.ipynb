{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92e9c08a",
   "metadata": {},
   "source": [
    "# Plotting synthesized signals\n",
    "\n",
    "The scope of `pyLeTalker` is to generate a set of signals, most notably the radiated sound pressure signal or acoustic signal in short. Visualization of the synthesized signals must be done through third-party library.\n",
    "\n",
    "Both [lt.sim()](../api_basic.rst#letalker.sim) and [lt.sim_kinematic()](../api_basic.rst#letalker.sim_kinematic) functions return two objects: `pout` and `res`. The former is a length-`N` vector of the acoustic signal samples at the system sampling rate, which could be found as `lt.fs`. The `N` is the number of samples that you requested when calling [lt.sim()](../api_basic.rst#letalker.sim) or [lt.sim_kinematic()](../api_basic.rst#letalker.sim_kinematic) function. The second output `res` is a dict of simulation results generated by each of 5 elements of the model: `res['lungs']`, `res['trachea']`, `res['vocalfolds']`, `res['vocaltract']`, and `res['lips']`. These `Results` objects host both the element configurations as well as recorded samples of their internal signals.\n",
    "\n",
    "This example demonstrates how to plot the simulation outcomes using [Matplotlib](https://matplotlib.org/). If you are not familiar with Matplotlib, please follow [their Getting Started Guide](https://matplotlib.org/stable/users/getting_started/) to install the library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac0622d",
   "metadata": {},
   "source": [
    "We start out by importing `letalker` and `matplotlib`. We use the shortened prefix (`lt.`) to access `letalker` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import letalker as lt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ccb954",
   "metadata": {},
   "source": [
    "## Plotting acoustic waveform and its spectrum\n",
    "\n",
    "For the sake of demonstration, let's synthesize /a/ vowel for 100 milliseconds at $f_o =$ 100 Hz (or simulating the first 10 vocal cycles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 0.1 # duration in seconds\n",
    "N = round(lt.fs*T) # =4410, number of samples to simulate\n",
    "fo = 100 # fundamental frequency in Hz\n",
    "\n",
    "pout, res = lt.sim_kinematic(N, fo, \"aa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01afb63",
   "metadata": {},
   "source": [
    "While we can plot the acoustic signal as a function of sample index, it's more intuitive to have the $x$-axis in seconds. Every `Results` object in the `res` dict contains `ts` item which is the corresponding time vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c9ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = res['lips'].ts # grabbing the time vector from lips element\n",
    "\n",
    "plt.plot(t,pout)\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('Radiated Sound Pressure');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e42bf",
   "metadata": {},
   "source": [
    "To plot the spectrum of the acoustic signal, we use [plt.magnitude_spectrum()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.magnitude_spectrum.html#matplotlib.pyplot.magnitude_spectrum) function. By default, it shows the frequency content up to the Nyquist frequency (i.e., the half of the sampling rate) which is typically too large to observe human voice behavior. So, we use [plt.xlim()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xlim) to only show the frequency content up to 4 kHz (or showing the first 40 harmonics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.magnitude_spectrum(pout, \n",
    "                       Fs=lt.fs,     # sampling rate\n",
    "                       pad_to=lt.fs, # set the resolution to be 1 Hz\n",
    "                       scale=\"dB\")   # alternately you can use \"linear\"\n",
    "plt.xlim(0, 4000);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddbd51e",
   "metadata": {},
   "source": [
    "## Plotting acoustic, glottal flow, and glottal area\n",
    "\n",
    "Now, let's create a matrix of plots showing acoustic, glottal flow, and glottal area; both their waveforms and spectra.\n",
    "\n",
    "The glottal flow (`ug`) and glottal area (`glottal_area`) are given in the results of the vocal-folds element: `res['vocalfolds']`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69184f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = res['vocalfolds'].glottal_area\n",
    "ug = res['vocalfolds'].ug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c9720",
   "metadata": {},
   "source": [
    "Let's layout the output to have 3 rows of signals and 2 columns (time and frequency domain) using [plt.subplots()](https://matplotlib.org/stable/api/_as_gen/matplotlib.figure.Figure.subplots.html#matplotlib.figure.Figure.subplots). With increased number of plots, we use a larger figure size (14 inches by 8 inches or 1344 pixels by 768 pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee390c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, sharex=\"col\", figsize=[14, 8])\n",
    "\n",
    "for label, x, (tax, fax) in zip(\n",
    "    (\"glottal area $A_g$\", \"glottal flow $U_g$\", \"radiated pressure $P_{Out}$\"),\n",
    "    (ga, ug, pout),\n",
    "    axes,\n",
    "):\n",
    "    tax.plot(t, x)\n",
    "    tax.set_ylabel(label)\n",
    "    fax.magnitude_spectrum(x, Fs=lt.fs, pad_to=lt.fs, scale=\"dB\")\n",
    "    fax.set_xlabel(\"\") # remove automatically inserted x-axis labels\n",
    "\n",
    "axes[0, 0].set_title(\"time-domain\")\n",
    "axes[0, 1].set_title(\"frequency-domain\")\n",
    "axes[-1, 0].set_xlabel(\"time (s)\")\n",
    "axes[-1, 1].set_xlim((0, 4000))\n",
    "axes[-1, 1].set_xlabel(\"frequency (Hz)\")\n",
    "fig.align_ylabels(axes[:, 0])\n",
    "plt.tight_layout() # useful function to automatically adjust the axes margins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d33b07",
   "metadata": {},
   "source": [
    "Finally, you can use [plt.savefig()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html#matplotlib.pyplot.savefig) to save the last figure as an image or `fig.savefig()` to specify a specific figure object. To save the above figure as `my_pyLeTalker_plot.png`, you need to run the following code:\n",
    "\n",
    "```python\n",
    "plt.savefig('my_pyLeTalker_plot.png')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4eec7",
   "metadata": {},
   "source": [
    "## Plotting spectrogram\n",
    "\n",
    "Spectrogram is an important signal visualization to illustrate the spectro-temporal behavior. For this, we can use [plt.specgram()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.specgram.html).\n",
    "\n",
    "To make the spectrogram a bit more interesting, let's run another simulation with a 1-second duration and design an $f_o$ contour with [lt.Interpolator](../api_basic.rst#letalker.Interpolator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59e13c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1\n",
    "N = round(T * lt.fs)\n",
    "\n",
    "fo = lt.Interpolator([0, 0.3, 0.5, 0.8, 1.0], [100, 90, 85, 110, 120])\n",
    "pout1, res1 = lt.sim_kinematic(N, fo, \"aa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296f2e82",
   "metadata": {},
   "source": [
    "The default configuration (i.e., `plt.specgram(pout1, NFFT=nseg, Fs=lt.fs)`) is unfit to inspect the vocal behavior. For a better outcome, we need to set three additional critical arguments: `NFFT`, `noverlap`, and `pad_to`. Specifically, we aimed to evaluate spectrum with a 100-milliseond sliding window, which is captured every 10 millisecond. The spectrum is calculated with frequency sample resolution of 1 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79219779",
   "metadata": {},
   "outputs": [],
   "source": [
    "nseg = round(0.1 * lt.fs) # 100 ms in the number of samples\n",
    "noverlap = round(0.09 * lt.fs) # 10 ms offset to the number of samples overlapped\n",
    "nfft = lt.fs # sampling rate = \n",
    "\n",
    "plt.specgram(pout1, NFFT=nseg, Fs=lt.fs, pad_to=nfft, noverlap=noverlap)\n",
    "plt.plot(fo.ts(N), fo(N), \"r--\", label='$f_o$ input') # superimpose fo\n",
    "plt.ylim([0, 1000])\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.ylabel(\"frequency (Hz)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed115c51",
   "metadata": {},
   "source": [
    "Note that the spectrogram is aligned to the center of the sliding window, thus it spans from $t=$ 0.05 to 0.95 second. Meanwhile, the interpolated $f_o$ input spans from 0 to 1 second."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
